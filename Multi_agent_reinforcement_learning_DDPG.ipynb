{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOldfri1+V3Y71SXDB0+8IK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryan8912/Multi-agent_reinforcement_learning_DDPG/blob/main/Multi_agent_reinforcement_learning_DDPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIW5tcAsL4GJ",
        "outputId": "ef6a294c-33ab-4293-d0da-a8d49322f936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchrl\n",
            "  Downloading torchrl-0.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (3.1.0)\n",
            "Collecting tensordict>=0.6.0 (from torchrl)\n",
            "  Downloading tensordict-0.6.2-cp310-cp310-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.6.0->torchrl) (3.10.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0->torchrl) (3.0.2)\n",
            "Downloading torchrl-0.6.0-cp310-cp310-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.6.2-cp310-cp310-manylinux1_x86_64.whl (359 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.9/359.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensordict, torchrl\n",
            "Successfully installed tensordict-0.6.2 torchrl-0.6.0\n",
            "Collecting vmas\n",
            "  Downloading vmas-1.4.3.tar.gz (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from vmas) (2.5.1+cu121)\n",
            "Collecting pyglet<=1.5.27 (from vmas)\n",
            "  Downloading pyglet-1.5.27-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from vmas) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->vmas) (3.0.2)\n",
            "Downloading pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: vmas\n",
            "  Building wheel for vmas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vmas: filename=vmas-1.4.3-py3-none-any.whl size=251650 sha256=84d8e174df96763fe505fe18c78dea452dcad668ef70464cd953bfd1c1c6fffd\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/26/e7/4cea32dc0e5c830808affe26bfd854dc4fd6075939c46ba4f0\n",
            "Successfully built vmas\n",
            "Installing collected packages: pyglet, vmas\n",
            "Successfully installed pyglet-1.5.27 vmas-1.4.3\n",
            "Collecting pettingzoo==1.24.3 (from pettingzoo[mpe]==1.24.3)\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (1.26.4)\n",
            "Collecting gymnasium>=0.28.0 (from pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pygame==2.3.0 (from pettingzoo[mpe]==1.24.3)\n",
            "  Downloading pygame-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, pygame, gymnasium, pettingzoo\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 pettingzoo-1.24.3 pygame-2.3.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchrl\n",
        "!pip install vmas\n",
        "!pip install pettingzoo[mpe]==1.24.3\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import tempfile\n",
        "\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tensordict import TensorDictBase\n",
        "\n",
        "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
        "from torch import multiprocessing\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyMemmapStorage, RandomSampler, ReplayBuffer\n",
        "\n",
        "from torchrl.envs import (\n",
        "    check_env_specs,\n",
        "    ExplorationType,\n",
        "    PettingZooEnv,\n",
        "    RewardSum,\n",
        "    set_exploration_type,\n",
        "    TransformedEnv,\n",
        "    VmasEnv,\n",
        ")\n",
        "\n",
        "from torchrl.modules import (\n",
        "    AdditiveGaussianModule,\n",
        "    MultiAgentMLP,\n",
        "    ProbabilisticActor,\n",
        "    TanhDelta,\n",
        ")\n",
        "\n",
        "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
        "\n",
        "from torchrl.record import CSVLogger, PixelRenderTransform, VideoRecorder\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if we're building the doc, in which case disable video rendering\n",
        "try:\n",
        "    is_sphinx = __sphinx_build__\n",
        "except NameError:\n",
        "    is_sphinx = False"
      ],
      "metadata": {
        "id": "nkny01IeML25"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Devices\n",
        "is_fork = multiprocessing.get_start_method() ==\"fork\"\n",
        "device = (\n",
        "    torch.device(0)\n",
        "    if torch.cuda.is_available() and not is_fork\n",
        "    else torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "# Sampling\n",
        "frames_per_batch = 1_000 # Number of team frames collected per sampling iteration\n",
        "n_iters = 10 # Number of sampling and traning iterations\n",
        "total_frames = frames_per_batch * n_iters\n",
        "\n",
        "# We will stop training the evaders after this many iteration,\n",
        "# should be 0 <= iteration_when_stop_training_evaders <= n_iters\n",
        "iteration_when_stop_training_evadrs = n_iters // 2\n",
        "\n",
        "# Replay buffer\n",
        "memory_size = 1_000_000 # The replay buffer of each group can store this many frames\n",
        "\n",
        "# Training\n",
        "n_optimiser_steps = 100 # Number of optimization steps per training iteration\n",
        "train_batch_size = 128 # Number of frames trained in each optimiser step\n",
        "lr = 3e-4 # Learning rate\n",
        "max_grad_norm = 1.0 # Maximum norm for the gradients\n",
        "\n",
        "# DDPG\n",
        "gamma = 0.99 # Discount factor\n",
        "polyak_tau = 0.005 # Tau for the soft-update of the target network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tHIm6iqN3H3",
        "outputId": "6ac8707c-26ca-4171-942a-9c2582c0dbee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 100 # Environment steps before done\n",
        "n_chasers = 2\n",
        "n_evaders = 1\n",
        "n_obstacles = 2\n",
        "\n",
        "use_vmas = True # set this to true for a greate performance speedup\n",
        "if not use_vmas:\n",
        "  base_env = pettingZooEnv(\n",
        "      task=\"simple_tag_v3\",\n",
        "      parallel=True, # Use the parallel version\n",
        "      seed=seed,\n",
        "      # Scenario specific\n",
        "      continous_actions=True,\n",
        "      num_good=n_evaders,\n",
        "      num_adversaries=n_chasers,\n",
        "      num_obstacles=n_obstacles,\n",
        "      max_cycles=max_steps,\n",
        "  )\n",
        "else:\n",
        "  num_vmas_envs = (\n",
        "      frames_per_batch // max_steps\n",
        "  ) # Number of vectorized environments. frames_per_batch collection will be divided among these environments\n",
        "  base_env = VmasEnv(\n",
        "      scenario=\"simple_tag\",\n",
        "      num_envs=num_vmas_envs,\n",
        "      max_cycles=max_steps,\n",
        "      device=device,\n",
        "      seed=seed,\n",
        "      # Scenario specific\n",
        "      num_good_agents = n_evaders,\n",
        "      num_adversaries = n_chasers,\n",
        "      num_obstacles = n_obstacles,\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPbsF2YROdW4",
        "outputId": "3bf34220-b3e0-4dbb-b9b9-a6fefcbeca9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/vmas/simulator/utils.py:317: UserWarning: Scenario kwargs: {'max_cycles': 100, 'num_obstacles': 2} passed but not used by the scenario. This will turn into an error in future versions.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"group_map: {base_env.group_map}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-trLSKCeRVtb",
        "outputId": "424a6140-973f-40e5-e8b7-99391b9bedb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group_map: {'adversary': ['adversary_0', 'adversary_1'], 'agent': ['agent_0']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"action_spec:\", base_env.full_action_spec)\n",
        "print(\"reward_spec:\", base_env.full_reward_spec)\n",
        "print(\"done_spec:\", base_env.full_done_spec)\n",
        "print(\"observation_spec:\", base_env.observation_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW-atViJRdWy",
        "outputId": "13b4f31c-2c32-4583-a6aa-9863609bb350"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_spec: Composite(\n",
            "    adversary: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([10, 2, 2]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    agent: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([10, 1, 2]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 1])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "reward_spec: Composite(\n",
            "    adversary: Composite(\n",
            "        reward: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 2, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    agent: Composite(\n",
            "        reward: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 1, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 1])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "done_spec: Composite(\n",
            "    done: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cuda:0,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n",
            "observation_spec: Composite(\n",
            "    adversary: Composite(\n",
            "        observation: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 2, 14]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 2])),\n",
            "    agent: Composite(\n",
            "        observation: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 1, 12]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
            "            device=cuda:0,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cuda:0,\n",
            "        shape=torch.Size([10, 1])),\n",
            "    device=cuda:0,\n",
            "    shape=torch.Size([10]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"action_keys:\", base_env.action_keys)\n",
        "print(\"reward_keys:\", base_env.reward_keys)\n",
        "print(\"done_keys:\", base_env.done_keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SWYmmmPR23m",
        "outputId": "a09be18d-cc61-4ed7-9dd5-ab4bc3ab2c5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_keys: [('adversary', 'action'), ('agent', 'action')]\n",
            "reward_keys: [('adversary', 'reward'), ('agent', 'reward')]\n",
            "done_keys: ['done', 'terminated']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    RewardSum(\n",
        "        in_keys = base_env.reward_keys,\n",
        "        reset_keys=[\"_reset\"] * len(base_env.group_map.keys()),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "zad7xPd5S87j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkLcr9hXTUGT",
        "outputId": "b444e437-a255-4295-c47e-7688d6b18dd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-10 07:58:33,451 [torchrl][INFO] check_env_specs succeeded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_rollout_steps = 5\n",
        "rollout = env.rollout(n_rollout_steps)\n",
        "print(f\"rollout of {n_rollout_steps} steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTN37AqUTYB1",
        "outputId": "b808c090-5303-4c4d-f04f-95de14240dd4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rollout of 5 steps: TensorDict(\n",
            "    fields={\n",
            "        adversary: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 5, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 5, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        agent: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 5, 1, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 5, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 5, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5, 1]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                adversary: TensorDict(\n",
            "                    fields={\n",
            "                        episode_reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        observation: Tensor(shape=torch.Size([10, 5, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        reward: Tensor(shape=torch.Size([10, 5, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "                    batch_size=torch.Size([10, 5, 2]),\n",
            "                    device=cuda:0,\n",
            "                    is_shared=True),\n",
            "                agent: TensorDict(\n",
            "                    fields={\n",
            "                        episode_reward: Tensor(shape=torch.Size([10, 5, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        observation: Tensor(shape=torch.Size([10, 5, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                        reward: Tensor(shape=torch.Size([10, 5, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "                    batch_size=torch.Size([10, 5, 1]),\n",
            "                    device=cuda:0,\n",
            "                    is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 5]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10, 5]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Shape of the rollout TensorDict: torch.Size([10, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy_modules = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_policy = True  # Can change this based on the group\n",
        "\n",
        "    policy_net = MultiAgentMLP(\n",
        "        n_agent_inputs=env.observation_spec[group, \"observation\"].shape[\n",
        "            -1\n",
        "        ],  # n_obs_per_agent\n",
        "        n_agent_outputs=env.full_action_spec[group, \"action\"].shape[\n",
        "            -1\n",
        "        ],  # n_actions_per_agents\n",
        "        n_agents=len(agents),  # Number of agents in the group\n",
        "        centralised=False,  # the policies are decentralised (i.e., each agent will act from its local observation)\n",
        "        share_params=share_parameters_policy,\n",
        "        device=device,\n",
        "        depth=2,\n",
        "        num_cells=256,\n",
        "        activation_class=torch.nn.Tanh,\n",
        "    )\n",
        "\n",
        "    # Wrap the neural network in a :class:`~tensordict.nn.TensorDictModule`.\n",
        "    # This is simply a module that will read the ``in_keys`` from a tensordict, feed them to the\n",
        "    # neural networks, and write the\n",
        "    # outputs in-place at the ``out_keys``.\n",
        "\n",
        "    policy_module = TensorDictModule(\n",
        "        policy_net,\n",
        "        in_keys=[(group, \"observation\")],\n",
        "        out_keys=[(group, \"param\")],\n",
        "    )  # We just name the input and output that the network will read and write to the input tensordict\n",
        "    policy_modules[group] = policy_module"
      ],
      "metadata": {
        "id": "bZTpIhM2Tx1i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    policy = ProbabilisticActor(\n",
        "        module=policy_modules[group],\n",
        "        spec=env.full_action_spec[group, \"action\"],\n",
        "        in_keys=[(group, \"param\")],\n",
        "        out_keys=[(group, \"action\")],\n",
        "        distribution_class=TanhDelta,\n",
        "        distribution_kwargs={\n",
        "            \"low\": env.full_action_spec[group, \"action\"].space.low,\n",
        "            \"high\": env.full_action_spec[group, \"action\"].space.high,\n",
        "        },\n",
        "        return_log_prob=False,\n",
        "    )\n",
        "    policies[group] = policy"
      ],
      "metadata": {
        "id": "mbAWxtyuV0ly"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exploration_policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    exploration_policy = TensorDictSequential(\n",
        "        policies[group],\n",
        "        AdditiveGaussianModule(\n",
        "            spec=policies[group].spec,\n",
        "            annealing_num_steps=total_frames\n",
        "            // 2,  # Number of frames after which sigma is sigma_end\n",
        "            action_key=(group, \"action\"),\n",
        "            sigma_init=0.9,  # Initial value of the sigma\n",
        "            sigma_end=0.1,  # Final value of the sigma\n",
        "        ),\n",
        "    )\n",
        "    exploration_policies[group] = exploration_policy"
      ],
      "metadata": {
        "id": "Hq-N2K5NW46y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critics = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_critic = True  # Can change for each group\n",
        "    MADDPG = True  # IDDPG if False, can change for each group\n",
        "\n",
        "    # This module applies the lambda function: reading the action and observation entries for the group\n",
        "    # and concatenating them in a new ``(group, \"obs_action\")`` entry\n",
        "    cat_module = TensorDictModule(\n",
        "        lambda obs, action: torch.cat([obs, action], dim=-1),\n",
        "        in_keys=[(group, \"observation\"), (group, \"action\")],\n",
        "        out_keys=[(group, \"obs_action\")],\n",
        "    )\n",
        "\n",
        "    critic_module = TensorDictModule(\n",
        "        module=MultiAgentMLP(\n",
        "            n_agent_inputs=env.observation_spec[group, \"observation\"].shape[-1]\n",
        "            + env.full_action_spec[group, \"action\"].shape[-1],\n",
        "            n_agent_outputs=1,  # 1 value per agent\n",
        "            n_agents=len(agents),\n",
        "            centralised=MADDPG,\n",
        "            share_params=share_parameters_critic,\n",
        "            device=device,\n",
        "            depth=2,\n",
        "            num_cells=256,\n",
        "            activation_class=torch.nn.Tanh,\n",
        "        ),\n",
        "        in_keys=[(group, \"obs_action\")],  # Read ``(group, \"obs_action\")``\n",
        "        out_keys=[\n",
        "            (group, \"state_action_value\")\n",
        "        ],  # Write ``(group, \"state_action_value\")``\n",
        "    )\n",
        "\n",
        "    critics[group] = TensorDictSequential(\n",
        "        cat_module, critic_module\n",
        "    )  # Run them in sequence"
      ],
      "metadata": {
        "id": "iZxvYWQZXuDy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_td = env.reset()\n",
        "for group, _agents in env.group_map.items():\n",
        "  print(\n",
        "      f\"Running value and policy for group '{group}':\",\n",
        "      critics[group](policies[group](reset_td)),\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOcCspA1QJif",
        "outputId": "bb634f60-0aa7-4335-9240-572dcbb0e860"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running value and policy for group 'adversary': TensorDict(\n",
            "    fields={\n",
            "        adversary: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        agent: TensorDict(\n",
            "            fields={\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 1]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Running value and policy for group 'agent': TensorDict(\n",
            "    fields={\n",
            "        adversary: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 2, 16]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 2]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        agent: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 1, 14]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                observation: Tensor(shape=torch.Size([10, 1, 12]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                param: Tensor(shape=torch.Size([10, 1, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
            "            batch_size=torch.Size([10, 1]),\n",
            "            device=cuda:0,\n",
            "            is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put exploration policies from each group in a sequence\n",
        "agents_exploration_policy = TensorDictSequential(*exploration_policies.values())\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    agents_exploration_policy,\n",
        "    device=device,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmiRVQqpQil2",
        "outputId": "6a3a9835-280e-4a63-8921-d057ba9f1175"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffers = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    replay_buffer = ReplayBuffer(\n",
        "        storage=LazyMemmapStorage(\n",
        "            memory_size, device=\"cpu\" # Force device to be \"cpu\"\n",
        "        ),  # We will store up to memory_size multi-agent transitions\n",
        "        sampler=RandomSampler(),\n",
        "        batch_size=train_batch_size,  # We will sample batches of this size\n",
        "    )\n",
        "    replay_buffers[group] = replay_buffer"
      ],
      "metadata": {
        "id": "cYYD0V9JRC2F"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    loss_module = DDPGLoss(\n",
        "        actor_network=policies[group],  # Use the non-explorative policies\n",
        "        value_network=critics[group],\n",
        "        delay_value=True,  # Whether to use a target network for the value\n",
        "        loss_function=\"l2\",\n",
        "    )\n",
        "    loss_module.set_keys(\n",
        "        state_action_value=(group, \"state_action_value\"),\n",
        "        reward=(group, \"reward\"),\n",
        "        done=(group, \"done\"),\n",
        "        terminated=(group, \"terminated\"),\n",
        "    )\n",
        "    loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
        "\n",
        "    losses[group] = loss_module\n",
        "\n",
        "target_updaters = {\n",
        "    group: SoftUpdate(loss, tau=polyak_tau) for group, loss in losses.items()\n",
        "}\n",
        "\n",
        "optimisers = {\n",
        "    group: {\n",
        "        \"loss_actor\": torch.optim.Adam(\n",
        "            loss.actor_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "        \"loss_value\": torch.optim.Adam(\n",
        "            loss.value_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "    }\n",
        "    for group, loss in losses.items()\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg5G8wmDRs1C",
        "outputId": "0e0a2839-5c6e-494c-91fd-6c08b74444e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_batch(batch: TensorDictBase) -> TensorDictBase:\n",
        "    \"\"\"\n",
        "    If the `(group, \"terminated\")` and `(group, \"done\")` keys are not present, create them by expanding\n",
        "    `\"terminated\"` and `\"done\"`.\n",
        "    This is needed to present them with the same shape as the reward to the loss.\n",
        "    \"\"\"\n",
        "    for group in env.group_map.keys():\n",
        "        keys = list(batch.keys(True, True))\n",
        "        group_shape = batch.get_item_shape(group)\n",
        "        nested_done_key = (\"next\", group, \"done\")\n",
        "        nested_terminated_key = (\"next\", group, \"terminated\")\n",
        "        if nested_done_key not in keys:\n",
        "            batch.set(\n",
        "                nested_done_key,\n",
        "                batch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n",
        "            )\n",
        "        if nested_terminated_key not in keys:\n",
        "            batch.set(\n",
        "                nested_terminated_key,\n",
        "                batch.get((\"next\", \"terminated\"))\n",
        "                .unsqueeze(-1)\n",
        "                .expand((*group_shape, 1)),\n",
        "            )\n",
        "    return batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M8kbrzMUWiY",
        "outputId": "1862e6de-8821-4b28-96ed-f9eb519e1cfd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = tqdm(\n",
        "    total=n_iters,\n",
        "    desc=\", \".join(\n",
        "        [f\"episode_reward_mean_{group} = 0\" for group in env.group_map.keys()]\n",
        "    ),\n",
        ")\n",
        "episode_reward_mean_map = {group: [] for group in env.group_map.keys()}\n",
        "train_group_map = copy.deepcopy(env.group_map)\n",
        "\n",
        "# Training/collection iterations\n",
        "for iteration, batch in enumerate(collector):\n",
        "    current_frames = batch.numel()\n",
        "    batch = process_batch(batch)  # Util to expand done keys if needed\n",
        "    # Loop over groups\n",
        "    for group in train_group_map.keys():\n",
        "        group_batch = batch.exclude(\n",
        "            *[\n",
        "                key\n",
        "                for _group in env.group_map.keys()\n",
        "                if _group != group\n",
        "                for key in [_group, (\"next\", _group)]\n",
        "            ]\n",
        "        )  # Exclude data from other groups\n",
        "        group_batch = group_batch.reshape(\n",
        "            -1\n",
        "        )  # This just affects the leading dimensions in batch_size of the tensordict\n",
        "        replay_buffers[group].extend(group_batch)\n",
        "\n",
        "        for _ in range(n_optimiser_steps):\n",
        "            subdata = replay_buffers[group].sample()\n",
        "\n",
        "            # Move subdata to the device where the model is located\n",
        "            subdata = subdata.to(device)\n",
        "\n",
        "            loss_vals = losses[group](subdata)\n",
        "\n",
        "            for loss_name in [\"loss_actor\", \"loss_value\"]:\n",
        "                loss = loss_vals[loss_name]\n",
        "                optimiser = optimisers[group][loss_name]\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Optional\n",
        "                params = optimiser.param_groups[0][\"params\"]\n",
        "                torch.nn.utils.clip_grad_norm_(params, max_grad_norm)\n",
        "\n",
        "                optimiser.step()\n",
        "                optimiser.zero_grad()\n",
        "\n",
        "            # Soft-update the target network\n",
        "            target_updaters[group].step()\n",
        "\n",
        "        # Exploration sigma anneal update\n",
        "        exploration_policies[group][-1].step(current_frames)\n",
        "\n",
        "    # Stop training a certain group when a condition is met (e.g., number of training iterations)\n",
        "    if iteration == iteration_when_stop_training_evaders:\n",
        "        del train_group_map[\"agent\"]\n",
        "\n",
        "    # Logging\n",
        "    # ... (rest of your code remains the same)\n",
        "    # Logging\n",
        "    for group in env.group_map.keys():\n",
        "        episode_reward_mean = (\n",
        "            batch.get((\"next\", group, \"episode_reward\"))[\n",
        "                batch.get((\"next\", group, \"done\"))\n",
        "            ]\n",
        "            .mean()\n",
        "            .item()\n",
        "        )\n",
        "        episode_reward_mean_map[group].append(episode_reward_mean)\n",
        "\n",
        "    pbar.set_description(\n",
        "        \", \".join(\n",
        "            [\n",
        "                f\"episode_reward_mean_{group} = {episode_reward_mean_map[group][-1]}\"\n",
        "                for group in env.group_map.keys()\n",
        "            ]\n",
        "        ),\n",
        "        refresh=False,\n",
        "    )\n",
        "    pbar.update()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "QB_oFX_HV8Fn",
        "outputId": "ba05e94d-eae2-4f8f-aca6-9ed473425022"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "episode_reward_mean_adversary = 0, episode_reward_mean_agent = 0:   0%|          | 0/10 [02:30<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'iteration_when_stop_training_evaders' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-491a0a122474>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Stop training a certain group when a condition is met (e.g., number of training iterations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miteration_when_stop_training_evaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtrain_group_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"agent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iteration_when_stop_training_evaders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 1)\n",
        "for i, group in enumerate(env.group_map.keys()):\n",
        "    axs[i].plot(episode_reward_mean_map[group], label=f\"Episode reward mean {group}\")\n",
        "    axs[i].set_ylabel(\"Reward\")\n",
        "    axs[i].axvline(\n",
        "        x=iteration_when_stop_training_evaders,\n",
        "        label=\"Agent (evader) stop training\",\n",
        "        color=\"orange\",\n",
        "    )\n",
        "    axs[i].legend()\n",
        "axs[-1].set_xlabel(\"Training iterations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "0m4MarTYZ2mL",
        "outputId": "6c980c60-1470-476a-c8c7-4f2fc329253a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'iteration_when_stop_training_evaders' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3f297e61343d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     axs[i].axvline(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_when_stop_training_evaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Agent (evader) stop training\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iteration_when_stop_training_evaders' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_vmas and not is_sphinx:\n",
        "    # Replace tmpdir with any desired path where the video should be saved\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        video_logger = CSVLogger(\"vmas_logs\", tmpdir, video_format=\"mp4\")\n",
        "        print(\"Creating rendering env\")\n",
        "        env_with_render = TransformedEnv(env.base_env, env.transform.clone())\n",
        "        env_with_render = env_with_render.append_transform(\n",
        "            PixelRenderTransform(\n",
        "                out_keys=[\"pixels\"],\n",
        "                # the np.ndarray has a negative stride and needs to be copied before being cast to a tensor\n",
        "                preproc=lambda x: x.copy(),\n",
        "                as_non_tensor=True,\n",
        "                # asking for array rather than on-screen rendering\n",
        "                mode=\"rgb_array\",\n",
        "            )\n",
        "        )\n",
        "        env_with_render = env_with_render.append_transform(\n",
        "            VideoRecorder(logger=video_logger, tag=\"vmas_rendered\")\n",
        "        )\n",
        "        with set_exploration_type(ExplorationType.DETERMINISTIC):\n",
        "            print(\"Rendering rollout...\")\n",
        "            env_with_render.rollout(100, policy=agents_exploration_policy)\n",
        "        print(\"Saving the video...\")\n",
        "        env_with_render.transform.dump()\n",
        "        print(\"Saved! Saved directory tree:\")\n",
        "        video_logger.print_log_dir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "Gd6bgxTMZ-15",
        "outputId": "368939c0-2ebb-4da0-ea26-d2cf443e3b18"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating rendering env\n",
            "Rendering rollout...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     from pyglet.gl import (\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mGL_BLEND\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/gl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mctypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_link_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mc_ptrdiff_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_glx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/gl/lib_glx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mgl_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mglu_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GLU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyglet/lib.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, *names, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Library \"%s\" not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Library \"GLU\" not found.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a1fda816bdad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mset_exploration_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExplorationType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDETERMINISTIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rendering rollout...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0menv_with_render\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magents_exploration_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving the video...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0menv_with_render\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   2598\u001b[0m             policy = _make_compatible_policy(\n\u001b[1;32m   2599\u001b[0m                 \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2600\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2601\u001b[0m                 \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m                 \u001b[0mfast_wrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mobservation_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \"\"\"\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mobservation_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"full_observation_spec\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobservation_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mobservation_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComposite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36moutput_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0moutput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlock_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0moutput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_output_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0moutput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_specs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36mtransform_output_spec\u001b[0;34m(self, output_spec)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_output_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensorSpec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0moutput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_output_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36mtransform_output_spec\u001b[0;34m(self, output_spec)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0moutput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         output_spec[\"full_observation_spec\"] = self.transform_observation_spec(\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0moutput_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_observation_spec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/recorder.py\u001b[0m in \u001b[0;36mtransform_observation_spec\u001b[0;34m(self, observation_spec)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mtd_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNonTensorData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/recorder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_tensordict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, env_index, agent_index_focus, visualize_when_rgb, plot_position_function, plot_position_function_precision, plot_position_function_range, plot_position_function_cmap_range, plot_position_function_cmap_alpha, plot_position_function_cmap_name)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headless\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheadless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_rendering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer_zoom\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/environment/environment.py\u001b[0m in \u001b[0;36m_init_rendering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_rendering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mvmas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         self.viewer = rendering.Viewer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vmas/simulator/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;34m\"Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Error occurred while running `from pyglet.gl import *`, HINT: make sure you have OpenGL installed. On Ubuntu, you can run 'apt-get install python3-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work:'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_FHZXE-aBiJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}